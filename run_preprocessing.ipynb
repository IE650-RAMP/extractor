{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing PDF - TXT - BAML - JSON\n",
    "\n",
    "This notbook is used to perform the extraction from the module catalogs. \n",
    "\n",
    "**How to use this notebook?**\n",
    "- set up the lists `splits` and `splits_modules`. the first one has the (starting) page numbers where to split the pdf. the second one has either 0 or 1 or 2 indecating if split at this index is about a module (1) or not (0) use (2) for any other information that does not need extraction at the moment\n",
    "    - 0 --> module overview\n",
    "    - 1 --> module details\n",
    "    - 2 --> anything else (not used at the moment)\n",
    "- run `folder = process_pdf(splits, splits_modules, PATH_TO_FILE, CATALOG_ABBREVIATION)`\n",
    "- run all the following cells as they are defined \n",
    "\n",
    "\n",
    "**The progress so far:**\n",
    "\n",
    "- MMDS (wima_wifo/MK_MMDS_2024_2025_14.06.2024) DONE\n",
    "- MMM (bwl/Module_Catalog_Mannheim_Master_in_Management_en) DONE\n",
    "- WIFO (wima_wifo/MK_MSc_Wifo__2024_25_16.10.2024.pdf) DONE\n",
    "- WIMA (Modulkatalog_Master_Wima_Mathe_2022_23) NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(\"./scripts\"))\n",
    "from scripts import process_pdf, merge_additional_files, process_catalog_overview, process_module_list, merge_json_files, process_module_files, dict_to_lists, fix_module_file\n",
    "\n",
    "import baml_client as client\n",
    "from baml_client import reset_baml_env_vars\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "reset_baml_env_vars(dict(os.environ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE USAGE: extract text with splits\n",
    "# List where to split the PDF. First page is 1, not 0!\n",
    "# MMDS\n",
    "split_dict = {\n",
    "    1: 0,\n",
    "    3: 2,\n",
    "    4: 0,\n",
    "    6: 1,\n",
    "    14: 0,\n",
    "    15: 1,\n",
    "    30: 1,\n",
    "    44: 0,\n",
    "    45: 2,\n",
    "    46: 1,\n",
    "    61: 1,\n",
    "    77: 0,\n",
    "    78: 1,\n",
    "    86: 0,\n",
    "    87: 1,\n",
    "    102: 0,\n",
    "    103: 1,\n",
    "    120: 1,\n",
    "    138: 1,\n",
    "    140: 2\n",
    "}\n",
    "splits, splits_modules = dict_to_lists(split_dict)\n",
    "\n",
    "# splits = [1, 6, 14, 15, 44, 46, 77, 78, 86, 87, 102, 103, 138, 140]\n",
    "# splits_modules = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0]\n",
    "\n",
    "folder = process_pdf(splits, splits_modules, './downloads/wima_wifo/MK_MMDS_2024_2025_20.08.2024.pdf', \"MMDS\")\n",
    "print(folder)\n",
    "\n",
    "# next run the other predefined cells to perform the BAML extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMM (BWL)\n",
    "split_dict = {\n",
    "    1: 2,\n",
    "    5: 0,\n",
    "    7: 2, \n",
    "    9: 0, \n",
    "    20: 1,\n",
    "    26: 1,\n",
    "    41: 1,\n",
    "    64: 1,\n",
    "    79: 1,\n",
    "    95: 1,\n",
    "    115: 1,\n",
    "    128: 1,\n",
    "    145: 1,\n",
    "    166: 1,\n",
    "    183: 1,\n",
    "    197: 1,\n",
    "    210: 1,\n",
    "    225: 1,\n",
    "    248: 2,\n",
    "    252: 2,\n",
    "    291: 1\n",
    "}\n",
    "\n",
    "splits, splits_modules = dict_to_lists(split_dict)\n",
    "folder = process_pdf(splits, splits_modules, \"./downloads/bwl/Module_Catalog_Mannheim_Master_in_Management_en.pdf\", \"MMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIFO\n",
    "split_dict = {\n",
    "    1: 0,\n",
    "    3: 2,\n",
    "    4: 0,\n",
    "    6: 1,\n",
    "    21: 0,\n",
    "    25: 1,\n",
    "    37: 1,\n",
    "    51: 1,\n",
    "    65: 1,\n",
    "    75: 2,\n",
    "    76: 1,\n",
    "    81: 0,\n",
    "    83: 1,\n",
    "    102: 1,\n",
    "    120: 0,\n",
    "    121: 1,\n",
    "    123: 2\n",
    "}\n",
    "splits, splits_modules = dict_to_lists(split_dict)\n",
    "\n",
    "# splits = [1, 6, 21, 25, 51, 75, 76, 81, 83, 120, 121, 123]\n",
    "# splits_modules = [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "folder = process_pdf(splits, splits_modules, './downloads/wima_wifo/MK_MSc_Wifo__2024_25_16.10.2024.pdf', 'WIFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIMA\n",
    "splits = []\n",
    "splits_modules = []\n",
    "folder = process_pdf(splits, splits_modules, './downloads/wima_wifo/Modulkatalog_Master_Wima_Mathe_2022_23.pdf', 'WIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2,\n",
       " 3: 1,\n",
       " 4: 2,\n",
       " 6: 15,\n",
       " 21: 4,\n",
       " 25: 12,\n",
       " 37: 14,\n",
       " 51: 14,\n",
       " 65: 10,\n",
       " 75: 1,\n",
       " 76: 5,\n",
       " 81: 2,\n",
       " 83: 19,\n",
       " 102: 18,\n",
       " 120: 1,\n",
       " 121: 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check split sizes\n",
    "distances = [j - i for i, j in zip(splits[:-1], splits[1:])]\n",
    "split_values = [j - i for i, j in zip(split_dict.keys(), list(split_dict.keys())[1:])]\n",
    "split_dict_filled = {k: v for k, v in zip(split_dict.keys(), split_values)}\n",
    "split_dict_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All '_additional_other' files have been merged into output/20241120_212121_WIFO/merged_additional_other.txt\n",
      "All '_additional_overview' files have been merged into output/20241120_212121_WIFO/merged_additional_overview.txt\n"
     ]
    }
   ],
   "source": [
    "# Merge all files that are not related to modules\n",
    "merge_additional_files(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract study programm overview from 'addtional' file using BAML\n",
    "process_catalog_overview(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['split_7_modules.txt', 'split_14_modules.txt', 'split_8_modules.txt', 'split_11_modules.txt', 'split_4_modules.txt', 'split_16_modules.txt', 'split_13_modules.txt', 'split_6_modules.txt', 'split_9_modules.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_7_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  11%|█         | 1/9 [00:25<03:24, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_14_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  22%|██▏       | 2/9 [00:58<03:29, 29.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_8_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  33%|███▎      | 3/9 [01:29<03:01, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_11_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  44%|████▍     | 4/9 [01:42<01:56, 23.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_4_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  56%|█████▌    | 5/9 [02:06<01:35, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_16_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  67%|██████▋   | 6/9 [02:10<00:51, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_13_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  78%|███████▊  | 7/9 [02:37<00:40, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_6_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files:  89%|████████▉ | 8/9 [03:00<00:21, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing file: output/20241120_212121_WIFO/split_9_modules.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing module files: 100%|██████████| 9/9 [03:27<00:00, 23.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract content from module files using BAML\n",
    "process_module_files(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged JSON file created at: output/20241120_212121_WIFO/merged_modules.json\n"
     ]
    }
   ],
   "source": [
    "# Merge extracted modules to one file\n",
    "merge_json_files(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other code for manual fixes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = './output/20241118_222726_MMDS'\n",
    "# file = str(folder) + '/split_2_modules.txt'\n",
    "# file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_module_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of modules in modules list: 53\n",
      "number of modules in overview: 54\n",
      "4 IDs in overview but not in modules: {'IS_752', 'IS_742', 'IS_751', 'IS_722'}\n",
      "3 IDs in modules but not in overview: {'BI_656', 'DS_203', 'MAC_570'}\n"
     ]
    }
   ],
   "source": [
    "# REVIEW THE IDS IN CATALOG VS IN MODULE LIST\n",
    "\n",
    "folder_review = folder \n",
    "# folder_review = 'output/20241120_125015_MMM'\n",
    "\n",
    "\n",
    "# Get the file names from the folder\n",
    "merged_modules_file = os.path.join(folder_review, 'merged_modules.json')\n",
    "catalog_overview_file = os.path.join(folder_review, 'catalog_overview.json')\n",
    "\n",
    "# print number of modules in detailed list\n",
    "with open(merged_modules_file, 'r') as f:\n",
    "    data_modules = json.load(f)\n",
    "\n",
    "modules_len = len(data_modules['modules'])\n",
    "print(\"number of modules in modules list:\", modules_len)\n",
    "\n",
    "# print number of modules in overview\n",
    "with open(catalog_overview_file, 'r') as f:\n",
    "    data_overview = json.load(f)\n",
    "combined_length = sum(len(area['modules']) for area in data_overview['studyArea'])\n",
    "print(\"number of modules in overview:\", combined_length)\n",
    "\n",
    "\n",
    "# create a list of the ids in the overview\n",
    "overview_ids = [module['id'] for area in data_overview['studyArea'] for module in area['modules']]\n",
    "# print(overview_ids)\n",
    "\n",
    "# create a list of the ids in the data_modules\n",
    "modules_ids = [module['id'] for module in data_modules['modules']]\n",
    "# print(modules_ids)\n",
    "\n",
    "# Compare the lists and print the ids that are in one list but not in the other\n",
    "overview_ids_set = set(id.upper() for id in overview_ids)\n",
    "modules_ids_set = set(id.upper() for id in modules_ids)\n",
    "\n",
    "# IDs in overview but not in modules\n",
    "ids_in_overview_not_in_modules = overview_ids_set - modules_ids_set\n",
    "print(f\"{len(ids_in_overview_not_in_modules)} IDs in overview but not in modules:\", ids_in_overview_not_in_modules)\n",
    "\n",
    "# IDs in modules but not in overview\n",
    "ids_in_modules_not_in_overview = modules_ids_set - overview_ids_set\n",
    "print(f\"{len(ids_in_modules_not_in_overview)} IDs in modules but not in overview:\", ids_in_modules_not_in_overview)\n",
    "\n",
    "with open(os.path.join(folder_review, 'information.txt'), 'w') as info_file:\n",
    "    info_file.write(f\"Number of modules in modules list: {modules_len}\\n\")\n",
    "    info_file.write(f\"Number of modules in overview: {combined_length}\\n\")\n",
    "    info_file.write(f\"{len(ids_in_overview_not_in_modules)} IDs in overview but not in modules:\\n{ids_in_overview_not_in_modules}\\n\")\n",
    "    info_file.write(f\"{len(ids_in_modules_not_in_overview)} IDs in modules but not in overview:\\n{ids_in_modules_not_in_overview}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai pls help fix this mess\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "def fix_with_openai(ids_overview, ids_modules):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for dataprocessing. You responds with dicts or list but do not use explanitory text.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                    It is your task to compare two lists of ids. There is one correct list and one incorrect one. Some of the ids in the incorrect one might match and id of the correct list.\n",
    "                    It is your taks to fix the incorrect list. To do so return a dict (with \"\") where the key is the incorrect id and the value is a matching corrected id that is present in the correct list.\n",
    "                    Note that it can be possible that there is no option to correct the id in this case just write None (without \"\") in the value.\n",
    "                    This is the list with the correct ids: {ids_overview}\n",
    "                    This is the list with the incorrect ids: {ids_modules}       \n",
    "                    \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix IDS in Modules, assumes that overview is correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix ids in modules. this matches ids we have in the modules but that do not match the one in the overview. so it will assume that overview is the truth and adjust accordingly\n",
    "fix_dict = fix_with_openai(ids_in_overview_not_in_modules, ids_in_modules_not_in_overview)\n",
    "print(fix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "try:\n",
    "    parsed_dict = ast.literal_eval(fix_dict)\n",
    "    # Replace string \"None\" with actual Python None\n",
    "    parsed_dict = {k: (None if v == \"None\" else v) for k, v in parsed_dict.items()}\n",
    "    print(parsed_dict)\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing string to dictionary: {e}\")\n",
    "\n",
    "len(parsed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the merged_modules.json file\n",
    "with open(merged_modules_file, 'r') as f:\n",
    "    merged_modules_data = json.load(f)\n",
    "\n",
    "# Iterate through the list of dictionaries under the key 'modules'\n",
    "for module in merged_modules_data['modules']:\n",
    "    module_id = module['id']\n",
    "    if module_id in parsed_dict:\n",
    "        new_id = parsed_dict[module_id]\n",
    "        if new_id is not None:\n",
    "            module['id'] = new_id\n",
    "\n",
    "# Save the updated data back to the file\n",
    "with open(merged_modules_file, 'w') as f:\n",
    "    json.dump(merged_modules_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the merged_modules.json file\n",
    "# with open(merged_modules_file, 'r') as f:\n",
    "#     merged_modules_data = json.load(f)\n",
    "\n",
    "# # Iterate through the list of dictionaries under the key 'modules'\n",
    "# for module in merged_modules_data['modules']:\n",
    "#     module_id = module['id']\n",
    "#     if module_id in parsed_dict:\n",
    "#         new_id = parsed_dict[module_id]\n",
    "#         if new_id is not None:\n",
    "#             module['id'] = new_id\n",
    "\n",
    "#     # Check and update ids in requiredPrerequisiteModules\n",
    "#     updated_required_prerequisites = []\n",
    "#     for prereq_id in module['requiredPrerequisiteModules']:\n",
    "#         if prereq_id in parsed_dict:\n",
    "#             new_prereq_id = parsed_dict[prereq_id]\n",
    "#             if new_prereq_id is not None:\n",
    "#                 updated_required_prerequisites.append(new_prereq_id)\n",
    "#             else:\n",
    "#                 updated_required_prerequisites.append(prereq_id)\n",
    "#         else:\n",
    "#             updated_required_prerequisites.append(prereq_id)\n",
    "#     module['requiredPrerequisiteModules'] = updated_required_prerequisites\n",
    "\n",
    "#     # Check and update ids in optionalPrerequisiteModules\n",
    "#     updated_optional_prerequisites = []\n",
    "#     for prereq_id in module['optionalPrerequisiteModules']:\n",
    "#         if prereq_id in parsed_dict:\n",
    "#             new_prereq_id = parsed_dict[prereq_id]\n",
    "#             if new_prereq_id is not None:\n",
    "#                 updated_optional_prerequisites.append(new_prereq_id)\n",
    "#             else:\n",
    "#                 updated_optional_prerequisites.append(prereq_id)\n",
    "#         else:\n",
    "#             updated_optional_prerequisites.append(prereq_id)\n",
    "#     module['optionalPrerequisiteModules'] = updated_optional_prerequisites\n",
    "\n",
    "#     # Check and update ids in furtherModules\n",
    "#     updated_further_modules = []\n",
    "#     for further_module_id in module['furtherModules']:\n",
    "#         if further_module_id in parsed_dict:\n",
    "#             new_further_module_id = parsed_dict[further_module_id]\n",
    "#             if new_further_module_id is not None:\n",
    "#                 updated_further_modules.append(new_further_module_id)\n",
    "#             else:\n",
    "#                 updated_further_modules.append(further_module_id)\n",
    "#         else:\n",
    "#             updated_further_modules.append(further_module_id)\n",
    "#     module['furtherModules'] = updated_further_modules\n",
    "\n",
    "# # Save the updated data back to the file\n",
    "# with open(merged_modules_file, 'w') as f:\n",
    "#     json.dump(merged_modules_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix IDS in Overview, assumes that modules is correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_dict = fix_with_openai(ids_in_modules_not_in_overview, ids_in_overview_not_in_modules)\n",
    "print(fix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "try:\n",
    "    parsed_dict = ast.literal_eval(fix_dict)\n",
    "    # Replace string \"None\" with actual Python None\n",
    "    parsed_dict = {k: (None if v == \"None\" else v) for k, v in parsed_dict.items()}\n",
    "    print(parsed_dict)\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing string to dictionary: {e}\")\n",
    "\n",
    "len(parsed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the catalog overview file\n",
    "with open(catalog_overview_file, 'r') as f:\n",
    "    catalog_overview_data = json.load(f)\n",
    "\n",
    "# Go through all the modules and check if the id is in the keys of the parsed_dict\n",
    "for study_area in catalog_overview_data['studyArea']:\n",
    "    for module in study_area['modules']:\n",
    "        module_id = module['id']\n",
    "        if module_id in parsed_dict:\n",
    "            new_id = parsed_dict[module_id]\n",
    "            if new_id is not None:\n",
    "                module['id'] = new_id\n",
    "\n",
    "# Save the updated data back to the file\n",
    "with open(catalog_overview_file, 'w') as f:\n",
    "    json.dump(catalog_overview_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix a module file where not all modules where extracted correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_module_file('output/20241120_125015_MMM/split_13_modules.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module-catalog-extractor-N-kYjEbR-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
